{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "LAYER_TYPES = {\n",
        "    \"conv\": 1,\n",
        "    \"pool\": 2,\n",
        "    \"fc\": 3,\n",
        "    \"flatten\": 4\n",
        "}\n",
        "MAX_LAYERS = 10\n",
        "LAYER_VECTOR_SIZE = 7\n",
        "TOTAL_VECTOR_SIZE = MAX_LAYERS * LAYER_VECTOR_SIZE"
      ],
      "metadata": {
        "id": "hM2EwHPoWPl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "LAYER_TYPES = {\n",
        "    \"conv\": 1,\n",
        "    \"pool\": 2,\n",
        "    \"fc\": 3,\n",
        "    \"flatten\": 4\n",
        "}\n",
        "MAX_LAYERS = 10\n",
        "LAYER_VECTOR_SIZE = 7\n",
        "TOTAL_VECTOR_SIZE = MAX_LAYERS * LAYER_VECTOR_SIZE\n",
        "\n",
        "def vectorize_cnn(model):\n",
        "    vector = np.zeros(TOTAL_VECTOR_SIZE)\n",
        "    layer_index = 0\n",
        "\n",
        "    for name, layer in model.named_children():\n",
        "      if layer_index >= MAX_LAYERS:\n",
        "        break\n",
        "\n",
        "      layer_vector = np.zeros(LAYER_VECTOR_SIZE)\n",
        "      if isinstance(layer, nn.Conv2d):\n",
        "        layer_vector[0] = LAYER_TYPES[\"conv\"]\n",
        "        layer_vector[1] = layer.out_channels\n",
        "        layer_vector[2] = layer.kernel_size[0]\n",
        "        layer_vector[3] = layer.stride[0]\n",
        "        layer_vector[4] = layer.padding[0]\n",
        "      elif isinstance(layer, nn.MaxPool2d):\n",
        "        layer_vector[0] = LAYER_TYPES[\"pool\"]\n",
        "        layer_vector[1] = layer.kernel_size\n",
        "        layer_vector[2] = layer.stride\n",
        "      elif isinstance(layer, nn.Linear):\n",
        "        layer_vector[0] = LAYER_TYPES[\"fc\"]\n",
        "        layer_vector[1] = layer.out_features\n",
        "      elif isinstance(layer, nn.Flatten):\n",
        "        layer_vector[0] = LAYER_TYPES[\"flatten\"]\n",
        "\n",
        "      vector[layer_index * LAYER_VECTOR_SIZE:(layer_index + 1) * LAYER_VECTOR_SIZE] = layer_vector\n",
        "      layer_index+=1\n",
        "\n",
        "    return vector\n",
        "\n",
        "def create_cnn_from_vector(vector):\n",
        "    layers = []\n",
        "    current_out_channels = 1\n",
        "    for layer_index in range(MAX_LAYERS):\n",
        "        layer_vector = vector[layer_index * LAYER_VECTOR_SIZE:(layer_index + 1) * LAYER_VECTOR_SIZE]\n",
        "        layer_type = int(layer_vector[0])\n",
        "        if layer_type == 0:\n",
        "           continue\n",
        "        elif layer_type == LAYER_TYPES[\"conv\"]:\n",
        "            filters = int(layer_vector[1])\n",
        "            kernel_size = int(layer_vector[2])\n",
        "            stride = int(layer_vector[3])\n",
        "            padding = int(layer_vector[4])\n",
        "            layers.append(nn.Conv2d(current_out_channels, filters, kernel_size, stride=stride, padding=padding))\n",
        "            current_out_channels = filters\n",
        "        elif layer_type == LAYER_TYPES[\"pool\"]:\n",
        "          kernel_size = int(layer_vector[1])\n",
        "          stride = int(layer_vector[2])\n",
        "          layers.append(nn.MaxPool2d(kernel_size, stride=stride))\n",
        "        elif layer_type == LAYER_TYPES[\"flatten\"]:\n",
        "            layers.append(nn.Flatten())\n",
        "        elif layer_type == LAYER_TYPES[\"fc\"]:\n",
        "          out_features = int(layer_vector[1])\n",
        "\n",
        "          in_features = None\n",
        "          for i in range(len(layers)-1, -1, -1):\n",
        "             if isinstance(layers[i], nn.Conv2d):\n",
        "                 in_features = int(np.prod(layers[i].out_channels))\n",
        "                 break\n",
        "          if in_features is None:\n",
        "            in_features = current_out_channels * 28 * 28\n",
        "          layers.append(nn.Linear(in_features, out_features))\n",
        "          current_out_channels = out_features\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, 3, padding=1),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Conv2d(32, 64, 3, padding=1),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 7 *7, 128),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "vector = vectorize_cnn(model)\n",
        "print(\"Векторное представление:\", vector)\n",
        "recovered_model = create_cnn_from_vector(vector)\n",
        "print(\"Восстановленная архитектура:\", recovered_model)\n",
        "\n",
        "def vectorize_cnn(model):\n",
        "    vector = np.zeros(TOTAL_VECTOR_SIZE)\n",
        "    layer_index = 0\n",
        "\n",
        "    for name, layer in model.named_children():\n",
        "      if layer_index >= MAX_LAYERS:\n",
        "        break\n",
        "\n",
        "      layer_vector = np.zeros(LAYER_VECTOR_SIZE)\n",
        "      if isinstance(layer, nn.Conv2d):\n",
        "        layer_vector[0] = LAYER_TYPES[\"conv\"]\n",
        "        layer_vector[1] = layer.out_channels\n",
        "        layer_vector[2] = layer.kernel_size[0]\n",
        "        layer_vector[3] = layer.stride[0]\n",
        "        layer_vector[4] = layer.padding[0]\n",
        "      elif isinstance(layer, nn.MaxPool2d):\n",
        "        layer_vector[0] = LAYER_TYPES[\"pool\"]\n",
        "        layer_vector[1] = layer.kernel_size\n",
        "        layer_vector[2] = layer.stride\n",
        "      elif isinstance(layer, nn.Linear):\n",
        "        layer_vector[0] = LAYER_TYPES[\"fc\"]\n",
        "        layer_vector[1] = layer.out_features\n",
        "      elif isinstance(layer, nn.Flatten):\n",
        "        layer_vector[0] = LAYER_TYPES[\"flatten\"]\n",
        "\n",
        "      vector[layer_index * LAYER_VECTOR_SIZE:(layer_index + 1) * LAYER_VECTOR_SIZE] = layer_vector\n",
        "      layer_index+=1\n",
        "\n",
        "    return vector\n",
        "\n",
        "def create_cnn_from_vector(vector):\n",
        "    layers = []\n",
        "    current_out_channels = 1\n",
        "    for layer_index in range(MAX_LAYERS):\n",
        "        layer_vector = vector[layer_index * LAYER_VECTOR_SIZE:(layer_index + 1) * LAYER_VECTOR_SIZE]\n",
        "        layer_type = int(layer_vector[0])\n",
        "        if layer_type == 0:\n",
        "           continue\n",
        "        elif layer_type == LAYER_TYPES[\"conv\"]:\n",
        "            filters = int(layer_vector[1])\n",
        "            kernel_size = int(layer_vector[2])\n",
        "            stride = int(layer_vector[3])\n",
        "            padding = int(layer_vector[4])\n",
        "            layers.append(nn.Conv2d(current_out_channels, filters, kernel_size, stride=stride, padding=padding))\n",
        "            current_out_channels = filters\n",
        "        elif layer_type == LAYER_TYPES[\"pool\"]:\n",
        "          kernel_size = int(layer_vector[1])\n",
        "          stride = int(layer_vector[2])\n",
        "          layers.append(nn.MaxPool2d(kernel_size, stride=stride))\n",
        "        elif layer_type == LAYER_TYPES[\"flatten\"]:\n",
        "            layers.append(nn.Flatten())\n",
        "        elif layer_type == LAYER_TYPES[\"fc\"]:\n",
        "          out_features = int(layer_vector[1])\n",
        "\n",
        "          in_features = None\n",
        "          for i in range(len(layers)-1, -1, -1):\n",
        "             if isinstance(layers[i], nn.Conv2d):\n",
        "                 in_features = int(np.prod(layers[i].out_channels))\n",
        "                 break\n",
        "          if in_features is None:\n",
        "            in_features = current_out_channels * 28 * 28\n",
        "          layers.append(nn.Linear(in_features, out_features))\n",
        "          current_out_channels = out_features\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, 3, padding=1),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Conv2d(32, 64, 3, padding=1),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 7 *7, 128),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "vector = vectorize_cnn(model)\n",
        "print(\"Векторное представление:\", vector)\n",
        "recovered_model = create_cnn_from_vector(vector)\n",
        "print(\"Восстановленная архитектура:\", recovered_model)\n",
        "\n",
        "model_layers = list(model.children())\n",
        "recovered_layers = list(recovered_model.children())\n",
        "for original, recovered in zip(model_layers, recovered_layers):\n",
        "  print(\"Original Layer: \", original)\n",
        "  print(\"Recovered Layer: \", recovered)\n",
        "  if type(original) == type(recovered):\n",
        "    if isinstance(original, nn.Conv2d):\n",
        "        print(original.out_channels == recovered.out_channels)\n",
        "    if isinstance(original, nn.Linear):\n",
        "        print(original.out_features == recovered.out_features)"
      ],
      "metadata": {
        "id": "FkF38UVqPLgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_cnn(model):\n",
        "    vector = np.zeros(TOTAL_VECTOR_SIZE)\n",
        "    layer_index = 0\n",
        "\n",
        "    for name, layer in model.named_children():\n",
        "      if layer_index >= MAX_LAYERS:\n",
        "        break\n",
        "\n",
        "      layer_vector = np.zeros(LAYER_VECTOR_SIZE)\n",
        "      if isinstance(layer, nn.Conv2d):\n",
        "        layer_vector[0] = LAYER_TYPES[\"conv\"]\n",
        "        layer_vector[1] = layer.out_channels\n",
        "        layer_vector[2] = layer.kernel_size[0]\n",
        "        layer_vector[3] = layer.stride[0]\n",
        "        layer_vector[4] = layer.padding[0]\n",
        "      elif isinstance(layer, nn.MaxPool2d):\n",
        "        layer_vector[0] = LAYER_TYPES[\"pool\"]\n",
        "        layer_vector[1] = layer.kernel_size\n",
        "        layer_vector[2] = layer.stride\n",
        "      elif isinstance(layer, nn.Linear):\n",
        "        layer_vector[0] = LAYER_TYPES[\"fc\"]\n",
        "        layer_vector[1] = layer.out_features\n",
        "      elif isinstance(layer, nn.Flatten):\n",
        "        layer_vector[0] = LAYER_TYPES[\"flatten\"]\n",
        "\n",
        "      vector[layer_index * LAYER_VECTOR_SIZE:(layer_index + 1) * LAYER_VECTOR_SIZE] = layer_vector\n",
        "      layer_index+=1\n",
        "\n",
        "    return vector\n",
        "\n",
        "def create_cnn_from_vector(vector):\n",
        "    layers = []\n",
        "    current_out_channels = 1\n",
        "    for layer_index in range(MAX_LAYERS):\n",
        "        layer_vector = vector[layer_index * LAYER_VECTOR_SIZE:(layer_index + 1) * LAYER_VECTOR_SIZE]\n",
        "        layer_type = int(layer_vector[0])\n",
        "        if layer_type == 0:\n",
        "           continue\n",
        "        elif layer_type == LAYER_TYPES[\"conv\"]:\n",
        "            filters = int(layer_vector[1])\n",
        "            kernel_size = int(layer_vector[2])\n",
        "            stride = int(layer_vector[3])\n",
        "            padding = int(layer_vector[4])\n",
        "            layers.append(nn.Conv2d(current_out_channels, filters, kernel_size, stride=stride, padding=padding))\n",
        "            current_out_channels = filters\n",
        "        elif layer_type == LAYER_TYPES[\"pool\"]:\n",
        "          kernel_size = int(layer_vector[1])\n",
        "          stride = int(layer_vector[2])\n",
        "          layers.append(nn.MaxPool2d(kernel_size, stride=stride))\n",
        "        elif layer_type == LAYER_TYPES[\"flatten\"]:\n",
        "            layers.append(nn.Flatten())\n",
        "        elif layer_type == LAYER_TYPES[\"fc\"]:\n",
        "          out_features = int(layer_vector[1])\n",
        "\n",
        "          in_features = None\n",
        "          for i in range(len(layers)-1, -1, -1):\n",
        "             if isinstance(layers[i], nn.Conv2d):\n",
        "                 in_features = int(np.prod(layers[i].out_channels))\n",
        "                 break\n",
        "          if in_features is None:\n",
        "            in_features = current_out_channels * 28 * 28\n",
        "          layers.append(nn.Linear(in_features, out_features))\n",
        "          current_out_channels = out_features\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "GCpqpN6roAVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, 3, padding=1),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Conv2d(32, 64, 3, padding=1),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 7 *7, 128),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "vector = vectorize_cnn(model)\n",
        "print(\"Векторное представление:\", vector)\n",
        "recovered_model = create_cnn_from_vector(vector)\n",
        "print(\"Восстановленная архитектура:\", recovered_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v8_lx3IoALC",
        "outputId": "cc84c853-dc8f-4edb-f9b0-1577de6978d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Векторное представление: [  1.  32.   3.   1.   1.   0.   0.   2.   2.   2.   0.   0.   0.   0.\n",
            "   1.  64.   3.   1.   1.   0.   0.   2.   2.   2.   0.   0.   0.   0.\n",
            "   4.   0.   0.   0.   0.   0.   0.   3. 128.   0.   0.   0.   0.   0.\n",
            "   3.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "Восстановленная архитектура: Sequential(\n",
            "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (6): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_layers = list(model.children())\n",
        "recovered_layers = list(recovered_model.children())\n",
        "for original, recovered in zip(model_layers, recovered_layers):\n",
        "  print(\"Original Layer: \", original)\n",
        "  print(\"Recovered Layer: \", recovered)\n",
        "  if type(original) == type(recovered):\n",
        "    if isinstance(original, nn.Conv2d):\n",
        "        print(original.out_channels == recovered.out_channels)\n",
        "    if isinstance(original, nn.Linear):\n",
        "        print(original.out_features == recovered.out_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3cD1GTmV-lH",
        "outputId": "d9745688-72de-465d-a9f5-cb68709680f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Layer:  Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "Recovered Layer:  Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "True\n",
            "Original Layer:  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Recovered Layer:  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Original Layer:  Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "Recovered Layer:  Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "True\n",
            "Original Layer:  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Recovered Layer:  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Original Layer:  Flatten(start_dim=1, end_dim=-1)\n",
            "Recovered Layer:  Flatten(start_dim=1, end_dim=-1)\n",
            "Original Layer:  Linear(in_features=3136, out_features=128, bias=True)\n",
            "Recovered Layer:  Linear(in_features=64, out_features=128, bias=True)\n",
            "True\n",
            "Original Layer:  Linear(in_features=128, out_features=10, bias=True)\n",
            "Recovered Layer:  Linear(in_features=64, out_features=10, bias=True)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncLKQJecrkZF",
        "outputId": "a4b5e083-7c4a-4931-a842-49e75e720f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import optuna"
      ],
      "metadata": {
        "id": "g11p7mC4RBxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ9d5EpERE38",
        "outputId": "c7f88a7e-4a46-4c84-8004-bbb4c99f953d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_layers, filters_base, hidden_size, dropout_rate):\n",
        "        super(CNN, self).__init__()\n",
        "        self.features = nn.Sequential()\n",
        "        in_channels = 3\n",
        "        kernel_size_base = 3\n",
        "        for i in range(num_layers):\n",
        "           filters = filters_base * (2 ** i)\n",
        "           kernel_size = kernel_size_base\n",
        "           self.features.append(nn.Conv2d(in_channels, filters, kernel_size=kernel_size, padding=1))\n",
        "           self.features.append(nn.ReLU())\n",
        "           self.features.append(nn.MaxPool2d(2, 2))\n",
        "           in_channels = filters\n",
        "        self.features.append(nn.AdaptiveAvgPool2d((4, 4)))\n",
        "        self.features.append(nn.Flatten())\n",
        "        self.classifier = nn.Sequential(\n",
        "          nn.Linear(in_channels * 4 * 4, hidden_size),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout_rate),\n",
        "          nn.Linear(hidden_size, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ECrKHzhhRKII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, optimizer, criterion, trainloader, testloader, epochs=10, device=\"cpu\"):\n",
        "  model.to(device)\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  return correct / total"
      ],
      "metadata": {
        "id": "p0NP2zHyRKBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 5)\n",
        "    filters_base = trial.suggest_int(\"filters_base\", 16, 64, step=16)\n",
        "    hidden_size = trial.suggest_int(\"hidden_size\", 128, 512, step=128)\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = CNN(num_layers, filters_base, hidden_size, dropout_rate)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    accuracy = train_and_evaluate(model, optimizer, criterion, trainloader, testloader, epochs=5, device=device)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "uKm-TgbdRWIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Лучшие параметры: \", study.best_params)\n",
        "print(\"Лучшая точность: \", study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdII1VrT7N5U",
        "outputId": "90595f12-776f-44f8-9eab-9aac42979413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-26 09:21:57,794] A new study created in memory with name: no-name-4c6d08d4-f9a7-4460-ab52-75660e188dbc\n",
            "[I 2024-12-26 09:23:11,843] Trial 0 finished with value: 0.539 and parameters: {'num_layers': 2, 'filters_base': 16, 'hidden_size': 384, 'dropout_rate': 0.40564936441436944, 'learning_rate': 0.0001495091712181927}. Best is trial 0 with value: 0.539.\n",
            "[I 2024-12-26 09:24:29,627] Trial 1 finished with value: 0.7343 and parameters: {'num_layers': 3, 'filters_base': 16, 'hidden_size': 512, 'dropout_rate': 0.4236711628142462, 'learning_rate': 0.001418790270493617}. Best is trial 1 with value: 0.7343.\n",
            "[I 2024-12-26 09:25:42,894] Trial 2 finished with value: 0.5662 and parameters: {'num_layers': 2, 'filters_base': 16, 'hidden_size': 256, 'dropout_rate': 0.4105061656951673, 'learning_rate': 0.0002819111732909902}. Best is trial 1 with value: 0.7343.\n",
            "[I 2024-12-26 09:27:09,682] Trial 3 finished with value: 0.6856 and parameters: {'num_layers': 5, 'filters_base': 16, 'hidden_size': 512, 'dropout_rate': 0.3441553384269377, 'learning_rate': 0.00034825743248398876}. Best is trial 1 with value: 0.7343.\n",
            "[I 2024-12-26 09:28:34,331] Trial 4 finished with value: 0.731 and parameters: {'num_layers': 2, 'filters_base': 64, 'hidden_size': 256, 'dropout_rate': 0.36755297198310666, 'learning_rate': 0.0015725253940056694}. Best is trial 1 with value: 0.7343.\n",
            "[I 2024-12-26 09:30:00,127] Trial 5 finished with value: 0.7305 and parameters: {'num_layers': 2, 'filters_base': 64, 'hidden_size': 512, 'dropout_rate': 0.3791726601537153, 'learning_rate': 0.002194112831896725}. Best is trial 1 with value: 0.7343.\n",
            "[I 2024-12-26 09:31:40,322] Trial 6 finished with value: 0.7381 and parameters: {'num_layers': 5, 'filters_base': 32, 'hidden_size': 128, 'dropout_rate': 0.23368031739568992, 'learning_rate': 0.0008108322487784352}. Best is trial 6 with value: 0.7381.\n",
            "[I 2024-12-26 09:33:05,047] Trial 7 finished with value: 0.6151 and parameters: {'num_layers': 2, 'filters_base': 64, 'hidden_size': 256, 'dropout_rate': 0.4090589311097449, 'learning_rate': 0.00015337041131936318}. Best is trial 6 with value: 0.7381.\n",
            "[I 2024-12-26 09:34:44,948] Trial 8 finished with value: 0.7725 and parameters: {'num_layers': 4, 'filters_base': 64, 'hidden_size': 384, 'dropout_rate': 0.22747508141425882, 'learning_rate': 0.0006052457571694114}. Best is trial 8 with value: 0.7725.\n",
            "[I 2024-12-26 09:36:10,603] Trial 9 finished with value: 0.6761 and parameters: {'num_layers': 5, 'filters_base': 16, 'hidden_size': 128, 'dropout_rate': 0.21229853236727367, 'learning_rate': 0.00043348539063788993}. Best is trial 8 with value: 0.7725.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры:  {'num_layers': 4, 'filters_base': 64, 'hidden_size': 384, 'dropout_rate': 0.22747508141425882, 'learning_rate': 0.0006052457571694114}\n",
            "Лучшая точность:  0.7725\n"
          ]
        }
      ]
    }
  ]
}